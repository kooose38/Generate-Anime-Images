{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport os \nimport time \nimport gc \nimport random \nimport warnings \nfrom pprint import pprint \nfrom PIL import Image \nimport cv2 \nfrom tqdm import tqdm \n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nfrom torch.utils.data import DataLoader, Dataset ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T09:10:51.377188Z","iopub.execute_input":"2021-11-26T09:10:51.377566Z","iopub.status.idle":"2021-11-26T09:10:51.386549Z","shell.execute_reply.started":"2021-11-26T09:10:51.377520Z","shell.execute_reply":"2021-11-26T09:10:51.385718Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# アニメ画像の生成タスク\n\nランダムなベクトルから顔画像を生成するモデルを学習させる。  \n`DCGAN`を使用する.\n","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:51.388324Z","iopub.execute_input":"2021-11-26T09:10:51.388798Z","iopub.status.idle":"2021-11-26T09:10:52.138662Z","shell.execute_reply.started":"2021-11-26T09:10:51.388760Z","shell.execute_reply":"2021-11-26T09:10:52.137797Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def random_seed(SEED):\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \n    \nconfig = {\n    \"model_name\": \"dcgan\", \n    \"device\": \"cuda:0\" if torch.cuda.is_available() else \"cpu\", \n    \"batch_size\": 128, \n    \"img_size\": 64, \n    \"z_fill\": 100, \n    \"n_channel\": 3, \n    \"mid_size\": 64, \n    \"epochs\": 50, \n    \"lr\": 0.0002, \n    \"beta1\": 0.5, \n    \"debug\": False, \n}\n\n\nROOT_PATH = \"../input/animefacedataset/images\"\nwarnings.simplefilter(\"ignore\")\npprint(config)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:52.142119Z","iopub.execute_input":"2021-11-26T09:10:52.142349Z","iopub.status.idle":"2021-11-26T09:10:52.155678Z","shell.execute_reply.started":"2021-11-26T09:10:52.142320Z","shell.execute_reply":"2021-11-26T09:10:52.154868Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(8, 8, figsize=(8, 8))\nax = axes.ravel()\n\nfor i, path in enumerate(os.listdir(ROOT_PATH)):\n    img_file_path = os.path.join(ROOT_PATH, path)\n    img = Image.open(img_file_path)\n    \n    ax[i].imshow(img)\n    ax[i].set_xticks([])\n    ax[i].set_yticks([])   \n    \n    if i >= 63:\n        break \n    \nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:52.158507Z","iopub.execute_input":"2021-11-26T09:10:52.158920Z","iopub.status.idle":"2021-11-26T09:10:55.249877Z","shell.execute_reply.started":"2021-11-26T09:10:52.158881Z","shell.execute_reply":"2021-11-26T09:10:55.249049Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class AnimeDataset(Dataset):\n    def __init__(self, root_path: str=ROOT_PATH, config=None):\n        self.root_path = root_path \n        self.img_files = os.listdir(self.root_path)\n        self.transform = transforms.Compose([\n            transforms.Resize(config[\"img_size\"]),\n            transforms.CenterCrop(config[\"img_size\"]), \n            transforms.ToTensor(), \n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n        \n    def decode(self, img_file):\n        img = Image.open(img_file)\n        return self.transform(img)\n        \n    def __getitem__(self, idx):\n        img_file = self.img_files[idx]\n        img = self.decode(os.path.join(self.root_path, img_file))\n        return img \n    \n    def __len__(self):\n        return len(self.img_files)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.251438Z","iopub.execute_input":"2021-11-26T09:10:55.251696Z","iopub.status.idle":"2021-11-26T09:10:55.261281Z","shell.execute_reply.started":"2021-11-26T09:10:55.251664Z","shell.execute_reply":"2021-11-26T09:10:55.260614Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.262611Z","iopub.execute_input":"2021-11-26T09:10:55.263089Z","iopub.status.idle":"2021-11-26T09:10:55.274092Z","shell.execute_reply.started":"2021-11-26T09:10:55.263048Z","shell.execute_reply":"2021-11-26T09:10:55.273293Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, config):\n        super(Generator, self).__init__()\n        ngf = config[\"mid_size\"]\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(config[\"z_fill\"], ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d( ngf, config[\"n_channel\"], 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n    def forward(self, input):\n        return self.main(input)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.275656Z","iopub.execute_input":"2021-11-26T09:10:55.276266Z","iopub.status.idle":"2021-11-26T09:10:55.287774Z","shell.execute_reply.started":"2021-11-26T09:10:55.276227Z","shell.execute_reply":"2021-11-26T09:10:55.287046Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"G = Generator(config)\nG.apply(weights_init)\n\na = torch.rand(2, 100, 1, 1) # インプットするベクトルサイズ\ny = G(a)\n\nfor bs in range(y.size()[0]):\n    plt.imshow(y[bs, :, :, :].detach().cpu().permute(1, 2, 0))\n    plt.axis(\"off\")\n    \n    break ","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.289369Z","iopub.execute_input":"2021-11-26T09:10:55.289824Z","iopub.status.idle":"2021-11-26T09:10:55.466172Z","shell.execute_reply.started":"2021-11-26T09:10:55.289787Z","shell.execute_reply":"2021-11-26T09:10:55.465072Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, config):\n        super(Discriminator, self).__init__()\n        ndf = config[\"mid_size\"]\n        self.main = nn.Sequential(\n            # input is (nc) x 64 x 64\n            nn.Conv2d(config[\"n_channel\"], ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.471380Z","iopub.execute_input":"2021-11-26T09:10:55.471831Z","iopub.status.idle":"2021-11-26T09:10:55.495559Z","shell.execute_reply.started":"2021-11-26T09:10:55.471779Z","shell.execute_reply":"2021-11-26T09:10:55.494373Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"D = Discriminator(config)\nD.apply(weights_init)\n\nprint(f\"input shape: {y.size()}\")\n\nwith torch.no_grad():\n    yy = D(y)\n    \nprint(f\"output shape: {yy.size()}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.504233Z","iopub.execute_input":"2021-11-26T09:10:55.504675Z","iopub.status.idle":"2021-11-26T09:10:55.586096Z","shell.execute_reply.started":"2021-11-26T09:10:55.504624Z","shell.execute_reply":"2021-11-26T09:10:55.585243Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### 訓練する\n正解データが存在しないのですべてのデータを使って学習させる。","metadata":{}},{"cell_type":"code","source":"criterion = nn.BCELoss()\n\nreal_label = 1 \nfake_label = 0 \n\nfixed_noise = torch.randn(64, config[\"z_fill\"], 1, 1, device=config[\"device\"])\n\noptimG = optim.Adam(G.parameters(), lr=config[\"lr\"], betas=(config[\"beta1\"], 0.999))\noptimD = optim.Adam(D.parameters(), lr=config[\"lr\"], betas=(config[\"beta1\"], 0.999))\n\ndataset = AnimeDataset(ROOT_PATH, config=config)\ndataloader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.587523Z","iopub.execute_input":"2021-11-26T09:10:55.588011Z","iopub.status.idle":"2021-11-26T09:10:55.624849Z","shell.execute_reply.started":"2021-11-26T09:10:55.587969Z","shell.execute_reply":"2021-11-26T09:10:55.624088Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"dataset[9]","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.626392Z","iopub.execute_input":"2021-11-26T09:10:55.626656Z","iopub.status.idle":"2021-11-26T09:10:55.637079Z","shell.execute_reply.started":"2021-11-26T09:10:55.626619Z","shell.execute_reply":"2021-11-26T09:10:55.636203Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"img_list = []\nG_losses = []\nD_losses = []\niters = 0\n\nG.to(config[\"device\"])\nD.to(config[\"device\"])\n\nG.train()\nD.train()\n\n\nfor e in range(2 if config[\"debug\"] else config[\"epochs\"]):\n    \n    for i, img in tqdm(enumerate(dataloader)):\n        real_img = img.to(config[\"device\"])\n        \n        # Discriminator の学習\n        # 本物画像は１に、偽物画像は0に分類するように学習する\n        D.zero_grad()\n        \n        bs = img.size()[0]\n        label = torch.full((bs, ), real_label, device=config[\"device\"], dtype=torch.float)\n        \n        output = D(real_img).view(-1)\n        \n        errD_real = criterion(output, label)\n        \n        errD_real.backward()\n        \n        noise = torch.randn(bs, config[\"z_fill\"], 1, 1, device=config[\"device\"])\n        \n        fake_img = G(noise)\n        label.fill_(fake_label)\n        \n        output = D(fake_img.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        \n        errD = errD_real + errD_fake\n        \n        optimD.step()\n        \n        # Generator の学習\n        # 偽物画像を1に分類するように学習する\n        G.zero_grad()\n        label.fill_(real_label)\n        \n        output = D(fake_img).view(-1)\n        errG = criterion(output, label)\n        \n        errG.backward()\n        optimG.step()\n        \n        if i % 1000 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n                  % (e, config[\"epochs\"], i, len(dataloader),\n                     errD.item(), errG.item()))\n\n            # Save Losses for plotting later\n            G_losses.append(errG.item())\n            D_losses.append(errD.item())\n\n        if (iters % 250 == 0) or ((e == config[\"epochs\"]-1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake_img = G(fixed_noise).detach().cpu()\n            img_list.append(vutils.make_grid(fake_img, padding=2, normalize=True))\n\n        iters += 1","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:10:55.638750Z","iopub.execute_input":"2021-11-26T09:10:55.639084Z","iopub.status.idle":"2021-11-26T10:03:28.629226Z","shell.execute_reply.started":"2021-11-26T09:10:55.639043Z","shell.execute_reply":"2021-11-26T10:03:28.628371Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Saved model weighted\n","metadata":{}},{"cell_type":"code","source":"os.makedirs(\"models\", exist_ok=True)\n\ntorch.save(G.state_dict(), f\"models/anime_G_{str(config['epochs'])}.pth\")\n\ntorch.save(D.state_dict(), f\"models/anime_D_{str(config['epochs'])}.pth\")","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:28.886647Z","iopub.execute_input":"2021-11-26T10:04:28.886921Z","iopub.status.idle":"2021-11-26T10:04:28.951109Z","shell.execute_reply.started":"2021-11-26T10:04:28.886891Z","shell.execute_reply":"2021-11-26T10:04:28.950347Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_losses,label=\"G\")\nplt.plot(D_losses,label=\"D\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:30.967632Z","iopub.execute_input":"2021-11-26T10:04:30.967910Z","iopub.status.idle":"2021-11-26T10:04:31.200061Z","shell.execute_reply.started":"2021-11-26T10:04:30.967878Z","shell.execute_reply":"2021-11-26T10:04:31.199357Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\nani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n\nHTML(ani.to_jshtml())","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:04:34.691828Z","iopub.execute_input":"2021-11-26T10:04:34.692366Z","iopub.status.idle":"2021-11-26T10:04:46.765397Z","shell.execute_reply.started":"2021-11-26T10:04:34.692331Z","shell.execute_reply":"2021-11-26T10:04:46.764705Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Final Results ","metadata":{}},{"cell_type":"code","source":"# Grab a batch of real images from the dataloader\nreal_batch = next(iter(dataloader))\n\n# Plot the real images\nplt.figure(figsize=(15,15))\nplt.subplot(1,2,1)\nplt.axis(\"off\")\nplt.title(\"Real Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch.to(config[\"device\"])[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n\n# Plot the fake images from the last epoch\nplt.subplot(1,2,2)\nplt.axis(\"off\")\nplt.title(\"Fake Images\")\nplt.imshow(np.transpose(img_list[-1],(1,2,0)))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-26T10:05:35.074861Z","iopub.execute_input":"2021-11-26T10:05:35.075569Z","iopub.status.idle":"2021-11-26T10:05:36.069213Z","shell.execute_reply.started":"2021-11-26T10:05:35.075532Z","shell.execute_reply":"2021-11-26T10:05:36.067443Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}